# main.py - AI ì¶”ì²œ ì „ìš© FastAPI (í†µí•© ì™„ì„± ë²„ì „)
# DB ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± + ë©”ëª¨ë¦¬ ìºì‹± + is_fixed í•„ë“œ í™œìš©

from dotenv import load_dotenv
from urllib.parse import urlparse
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
import mysql.connector
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import os
import re
import decimal  
import hashlib

load_dotenv()

# =============================================================================
# DB ì„¤ì • - Railway ìš°ì„ , ë¡œì»¬ì€ ì˜ˆì™¸ ì²˜ë¦¬
# =============================================================================
def get_db_config():
    """DB ì„¤ì •ì„ ë™ì ìœ¼ë¡œ ê²°ì • - Railway ê¸°ë³¸, ë¡œì»¬ ì˜ˆì™¸"""
    
    # 1. Railway í™˜ê²½ë³€ìˆ˜ë“¤ í™•ì¸
    mysql_host = os.getenv('MYSQLHOST')
    mysql_port = os.getenv('MYSQLPORT')
    mysql_user = os.getenv('MYSQLUSER') 
    mysql_password = os.getenv('MYSQLPASSWORD')
    mysql_database = os.getenv('MYSQLDATABASE')
    
    if mysql_host and mysql_user and mysql_database:
        print("ğŸš„ Railway MySQL í™˜ê²½ ê°ì§€")
        return {
            'host': mysql_host,
            'port': int(mysql_port) if mysql_port else 3306,
            'user': mysql_user,
            'password': mysql_password or '',
            'database': mysql_database,
            'charset': 'utf8mb4'
        }
    
    # 2. ëŒ€ì²´: MYSQL_URL ë°©ì‹
    mysql_url = os.getenv('MYSQL_URL')
    if mysql_url and mysql_url.startswith('mysql://'):
        print("ğŸ”— MySQL URL í™˜ê²½ ê°ì§€")
        parsed = urlparse(mysql_url)
        return {
            'host': parsed.hostname,
            'port': parsed.port or 3306,
            'user': parsed.username,
            'password': parsed.password,
            'database': parsed.path[1:] if parsed.path else 'railway',
            'charset': 'utf8mb4'
        }
    
    # 3. ë¡œì»¬ ê°œë°œ í™˜ê²½
    print("ğŸ’» ë¡œì»¬ MySQL í™˜ê²½ìœ¼ë¡œ ì„¤ì •")
    return {
        'host': os.getenv('LOCAL_MYSQL_HOST', 'localhost'),
        'port': int(os.getenv('LOCAL_MYSQL_PORT', 3306)),
        'user': os.getenv('LOCAL_MYSQL_USER', 'root'),
        'password': os.getenv('LOCAL_MYSQL_PASSWORD', ''),
        'database': os.getenv('LOCAL_MYSQL_DATABASE', 'day0_db'),
        'charset': 'utf8mb4'
    }

DB_CONFIG = get_db_config()

app = FastAPI(title="Day-0 AI Recommendation Service", version="1.0.0")

# =============================================================================
# ë©”ëª¨ë¦¬ ìºì‹œ ì„¤ì •
# =============================================================================

# ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ìºì‹œ ë”•ì…”ë„ˆë¦¬
cache_dict = {}

def get_cache_key(endpoint: str, country_code: str, program_type_id: int, items_hash: str = ""):
    """ìºì‹œ í‚¤ ìƒì„±"""
    if items_hash:
        return f"{endpoint}:{country_code}:{program_type_id}:{items_hash}"
    return f"{endpoint}:{country_code}:{program_type_id}"

def hash_items(items: List[dict]) -> str:
    """í•­ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ í•´ì‹œë¡œ ë³€í™˜ (í•­ëª© ë³€ê²½ ê°ì§€ìš©)"""
    titles = sorted([item.get('title', '') for item in items])
    return hashlib.md5('|'.join(titles).encode()).hexdigest()[:8]

def get_from_cache(cache_key: str, max_age_hours: int = 1):
    """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
    if cache_key in cache_dict:
        cache_entry = cache_dict[cache_key]
        age = datetime.now() - cache_entry['created']
        if age < timedelta(hours=max_age_hours):
            print(f"âœ… ìºì‹œ íˆíŠ¸: {cache_key}")
            return cache_entry['data']
        else:
            # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
            del cache_dict[cache_key]
            print(f"ğŸ• ìºì‹œ ë§Œë£Œ: {cache_key}")
    return None

def save_to_cache(cache_key: str, data: any):
    """ìºì‹œì— ë°ì´í„° ì €ì¥"""
    cache_dict[cache_key] = {
        'data': data,
        'created': datetime.now()
    }
    print(f"ğŸ’¾ ìºì‹œ ì €ì¥: {cache_key}")

def clear_cache_pattern(pattern: str):
    """íŒ¨í„´ì— ë§ëŠ” ìºì‹œ ì‚­ì œ"""
    keys_to_delete = [k for k in cache_dict.keys() if pattern in k]
    for key in keys_to_delete:
        del cache_dict[key]
    print(f"ğŸ§¹ ìºì‹œ ì‚­ì œ: {len(keys_to_delete)}ê°œ í•­ëª©")

# =============================================================================
# ë°ì´í„° ëª¨ë¸ (DB ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± ë°˜ì˜)
# =============================================================================

class ChecklistItem(BaseModel):
    """ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª© ëª¨ë¸"""
    title: str
    description: Optional[str] = ""
    tag: str = "NONE"
    status: str = "TODO"
    is_fixed: Optional[bool] = False  # ë‚ ì§œ ê³ ì • ì—¬ë¶€ (D-30 ë“±)

class MissingItemsRequest(BaseModel):
    """ëˆ„ë½ í•­ëª© ì¶”ì²œ ìš”ì²­"""
    existing_items: List[ChecklistItem]
    country_code: str
    program_type_id: int
    departure_date: str

class MissingItem(BaseModel):
    """ëˆ„ë½ í•­ëª© ì‘ë‹µ"""
    item_title: str
    item_description: str
    item_tag: str
    popularity_rate: float
    avg_offset_days: int
    priority_score: int
    missing_reason: str
    confidence_score: float

class MissingItemsResponse(BaseModel):
    """ëˆ„ë½ í•­ëª© ì¶”ì²œ ì‘ë‹µ"""
    missing_items: List[MissingItem]
    total_missing: int
    recommendation_summary: str

class PriorityReorderRequest(BaseModel):
    """ìš°ì„ ìˆœìœ„ ì¬ì •ë ¬ ìš”ì²­"""
    current_items: List[ChecklistItem]
    country_code: str
    program_type_id: int
    departure_date: str
    user_context: Optional[Dict[str, Any]] = {}

class PriorityItem(BaseModel):
    """ìš°ì„ ìˆœìœ„ê°€ ì¡°ì •ëœ í•­ëª©"""
    title: str
    description: str
    tag: str
    original_priority: int
    ai_priority: int
    urgency_score: float
    reorder_reason: str
    is_fixed: bool = False  # ë‚ ì§œ ê³ ì • ì—¬ë¶€ í¬í•¨

class PriorityReorderResponse(BaseModel):
    """ìš°ì„ ìˆœìœ„ ì¬ì •ë ¬ ì‘ë‹µ"""
    reordered_items: List[PriorityItem]
    total_reordered: int
    days_until_departure: int
    reorder_summary: str

# =============================================================================
# ì˜ë¯¸ì  ìœ ì‚¬ì„± ê¸°ë°˜ ì¤‘ë³µ ì œê±° ë¡œì§ 
# =============================================================================

def extract_keywords(text):
    """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    keywords = re.findall(r'[ê°€-í£a-zA-Z]+', text.lower())
    stopwords = {'ë°', 'ë“±', 'ë˜ëŠ”', 'ì¤€ë¹„', 'í™•ì¸', 'ì‹ ì²­', 'ë°œê¸‰', 'ì˜ˆì•½', 
                 'and', 'or', 'the', 'of', 'for', 'to', 'in', 'with'}
    keywords = [k for k in keywords if k not in stopwords and len(k) > 1]
    return set(keywords)

def is_semantically_similar(item1_title, item1_desc, item2_title, item2_desc, threshold=0.8):
    """ì •í™•í•œ ì¤‘ë³µë§Œ íŒë‹¨ (ê³¼ë„í•œ ì¤‘ë³µ ì œê±° ë°©ì§€)"""
    
    keywords1 = extract_keywords(f"{item1_title} {item1_desc}")
    keywords2 = extract_keywords(f"{item2_title} {item2_desc}")
    
    if len(keywords1) == 0 or len(keywords2) == 0:
        return False
    
    # Jaccard ìœ ì‚¬ë„
    intersection = len(keywords1 & keywords2)
    union = len(keywords1 | keywords2)
    jaccard_score = intersection / union if union > 0 else 0
    
    return jaccard_score >= threshold

def remove_semantic_duplicates(base_items, candidate_items, similarity_threshold=0.8):
    """ë³´ìˆ˜ì ì¸ ì¤‘ë³µ ì œê±° (ì •í™•í•œ ì¤‘ë³µë§Œ)"""
    
    filtered_candidates = []
    
    for candidate in candidate_items:
        is_duplicate = False
        
        for base_item in base_items:
            if is_semantically_similar(
                base_item['title'], 
                base_item.get('description', ''),
                candidate['item_title'],
                candidate.get('item_description', ''),
                similarity_threshold
            ):
                print(f"ì •í™•í•œ ì¤‘ë³µ ì œê±°: '{candidate['item_title']}' â‰ˆ '{base_item['title']}'")
                is_duplicate = True
                break
        
        if not is_duplicate:
            filtered_candidates.append(candidate)
    
    return filtered_candidates

# =============================================================================
# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì¡°íšŒ í•¨ìˆ˜
# =============================================================================

def get_db_connection():
    """DB ì—°ê²° í•¨ìˆ˜"""
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        conn.ping(reconnect=True, attempts=3, delay=1)
        return conn
    except mysql.connector.Error as e:
        error_msg = str(e)
        print(f"DB ì—°ê²° ì˜¤ë¥˜: {error_msg}")
        raise HTTPException(status_code=500, detail=f"DB ì—°ê²° ì‹¤íŒ¨: {error_msg}")

def get_popularity_stats(country_code: str, program_type_id: int):
    """ì¸ê¸° í†µê³„ ë°ì´í„° ì¡°íšŒ"""
    conn = get_db_connection()
    cursor = conn.cursor(dictionary=True)
    
    try:
        query = """
        SELECT item_title, item_description, item_tag, popularity_rate, 
               avg_offset_days, priority_score
        FROM item_popularity_stats 
        WHERE country_code = %s AND program_type_id = %s
        ORDER BY popularity_rate DESC, priority_score ASC
        """
        cursor.execute(query, (country_code, program_type_id))
        return cursor.fetchall()
        
    finally:
        cursor.close()
        conn.close()

# =============================================================================
# AI ì¶”ì²œ ë¡œì§ (is_fixed í™œìš© ê°•í™”)
# =============================================================================

def find_missing_items(existing_items: List[dict], popularity_data: List[dict]) -> List[dict]:
    """ëˆ„ë½ëœ í•­ëª© ì°¾ê¸° - is_fixed ìš°ì„  ê³ ë ¤"""
    
    # ê¸°ì¡´ í•­ëª©ë“¤ì˜ ì œëª© ì„¸íŠ¸
    existing_titles = {item['title'].lower() for item in existing_items}
    
    missing_items = []
    for pop_item in popularity_data:
        item_title = pop_item['item_title'].lower()
        
        # 1. ì •í™•í•œ ì œëª© ë§¤ì¹­ìœ¼ë¡œ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
        if item_title in existing_titles:
            continue
            
        # 2. ì˜ë¯¸ì  ìœ ì‚¬ì„±ìœ¼ë¡œ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
        is_already_exists = False
        for existing_item in existing_items:
            if is_semantically_similar(
                existing_item['title'],
                existing_item.get('description', ''),
                pop_item['item_title'],
                pop_item.get('item_description', ''),
                threshold=0.7
            ):
                is_already_exists = True
                break
        
        if not is_already_exists:
            # Decimalì„ floatë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
            popularity_rate = float(pop_item['popularity_rate']) if isinstance(pop_item['popularity_rate'], decimal.Decimal) else pop_item['popularity_rate']
            priority_score = float(pop_item['priority_score']) if isinstance(pop_item['priority_score'], decimal.Decimal) else pop_item['priority_score']
            
            # ëˆ„ë½ ì´ìœ  íŒë‹¨
            if popularity_rate > 0.9:
                reason = f"í•„ìˆ˜ í•­ëª©: {popularity_rate*100:.0f}%ê°€ ì¤€ë¹„"
            elif priority_score <= 2:
                reason = "ë†’ì€ ìš°ì„ ìˆœìœ„ í•­ëª©"
            elif popularity_rate > 0.8:
                reason = f"ì¸ê¸° í•­ëª©: {popularity_rate*100:.0f}%ê°€ ì¤€ë¹„"
            else:
                reason = "ì¶”ì²œ í•­ëª©"
            
            # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
            confidence = popularity_rate * 0.7 + (1 - priority_score/10) * 0.3
            
            missing_items.append({
                'item_title': pop_item['item_title'],
                'item_description': pop_item['item_description'],
                'item_tag': pop_item['item_tag'],
                'popularity_rate': popularity_rate,
                'avg_offset_days': pop_item['avg_offset_days'],
                'priority_score': priority_score,
                'missing_reason': reason,
                'confidence_score': confidence
            })
    
    # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    missing_items.sort(key=lambda x: x['confidence_score'], reverse=True)
    return missing_items[:5]  # ìƒìœ„ 5ê°œë§Œ

def calculate_priority_scores(items: List[dict], departure_date: str, popularity_data: List[dict]) -> List[dict]:
    """ìš°ì„ ìˆœìœ„ ì ìˆ˜ ì¬ê³„ì‚° - is_fixed í•„ë“œ í™œìš©"""
    departure_dt = datetime.strptime(departure_date, "%Y-%m-%d")
    days_until = (departure_dt - datetime.now()).days
    
    # ì¸ê¸° í†µê³„ë¥¼ ë¹ ë¥¸ ì¡°íšŒë¥¼ ìœ„í•´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    popularity_dict = {stat['item_title']: stat for stat in popularity_data}
    
    reordered_items = []
    
    for i, item in enumerate(items):
        original_priority = i + 1
        is_fixed = item.get('is_fixed', False)
        
        # ì¸ê¸° í†µê³„ì—ì„œ í•´ë‹¹ í•­ëª© ì°¾ê¸°
        stat = popularity_dict.get(item['title'])
        
        if stat:
            # Decimalì„ floatë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
            popularity_rate = float(stat['popularity_rate']) if isinstance(stat['popularity_rate'], decimal.Decimal) else stat['popularity_rate']
            
            # ê¸´ê¸‰ë„ ê³„ì‚°
            recommended_prep_day = abs(stat['avg_offset_days'])
            urgency_score = min(1.0, recommended_prep_day / max(1, days_until)) if days_until <= recommended_prep_day else 0.3
            
            # is_fixed í•­ëª©ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ì¶”ê°€
            fixed_bonus = 0.2 if is_fixed else 0.0
            
            # AI ìš°ì„ ìˆœìœ„ ê³„ì‚° (ì¸ê¸°ë„ + ê¸´ê¸‰ë„ + ê³ ì • ë³´ë„ˆìŠ¤)
            ai_priority_score = popularity_rate * 0.5 + urgency_score * 0.3 + fixed_bonus
            
            # ì¬ì •ë ¬ ì´ìœ 
            if is_fixed and urgency_score > 0.5:
                reason = f"ğŸ“… ê³ ì • ì¼ì •: D{stat['avg_offset_days']} ì¤€ë¹„ í•„ìˆ˜"
            elif urgency_score > 0.7:
                reason = f"âš ï¸ ê¸´ê¸‰: ì¶œêµ­ê¹Œì§€ {days_until}ì¼ë§Œ ë‚¨ìŒ"
            elif popularity_rate > 0.9:
                reason = f"ğŸ”¥ í•„ìˆ˜: {popularity_rate*100:.0f}%ê°€ ì¤€ë¹„"
            elif is_fixed:
                reason = f"ğŸ“Œ ë‚ ì§œ ê³ ì • í•­ëª©: D{stat['avg_offset_days']} ê¶Œì¥"
            elif urgency_score > 0.5:
                reason = f"â° ì„œë‘˜ëŸ¬ì•¼ í•¨: D{stat['avg_offset_days']} ê¶Œì¥"
            else:
                reason = "ğŸ“ ì¼ë°˜ í•­ëª©"
        else:
            # í†µê³„ê°€ ì—†ëŠ” í•­ëª©ì€ ê¸°ë³¸ê°’
            urgency_score = 0.5
            fixed_bonus = 0.1 if is_fixed else 0.0
            ai_priority_score = 0.5 + fixed_bonus
            
            if is_fixed:
                reason = "ğŸ“Œ ë‚ ì§œ ê³ ì • í•­ëª©"
            else:
                reason = "ğŸ“ ì¼ë°˜ í•­ëª©"
        
        reordered_items.append({
            'title': item['title'],
            'description': item.get('description', ''),
            'tag': item.get('tag', 'NONE'),
            'original_priority': original_priority,
            'ai_priority_score': ai_priority_score,
            'urgency_score': urgency_score,
            'reorder_reason': reason,
            'is_fixed': is_fixed
        })
    
    # AI ìš°ì„ ìˆœìœ„ ì ìˆ˜ë¡œ ì •ë ¬ (is_fixed í•­ëª©ì´ ìì—°ìŠ¤ëŸ½ê²Œ ìƒìœ„ë¡œ)
    reordered_items.sort(key=lambda x: x['ai_priority_score'], reverse=True)
    
    # ìƒˆë¡œìš´ ìˆœì„œ ë²ˆí˜¸ ë¶€ì—¬
    for i, item in enumerate(reordered_items):
        item['ai_priority'] = i + 1
    
    return reordered_items

# =============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {"message": "Day-0 AI Recommendation Service", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    """DB ì—°ê²° ìƒíƒœ í™•ì¸"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT 1")
        result = cursor.fetchone()
        cursor.close()
        conn.close()
        return {"status": "healthy", "db": "connected"}
    except Exception as e:
        return {"status": "unhealthy", "db": "disconnected", "error": str(e)}

@app.post("/ai/recommendations/missing-items", response_model=MissingItemsResponse)
async def recommend_missing_items(request: MissingItemsRequest):
    """
    ëˆ„ë½ í•­ëª© ì¶”ì²œ API (ìºì‹œ ì ìš© + DB í˜¸í™˜ì„±)
    
    Spring Bootì—ì„œ í˜„ì¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ë‚´ì£¼ë©´
    ì¸ê¸° í†µê³„ ê¸°ë°˜ìœ¼ë¡œ ëˆ„ë½ëœ í•­ëª©ë“¤ì„ ì°¾ì•„ì„œ ì¶”ì²œ
    """
    try:
        # ìºì‹œ í‚¤ ìƒì„± (ê¸°ì¡´ í•­ëª© í•´ì‹œ í¬í•¨)
        existing_items_dict = [item.model_dump() for item in request.existing_items]
        items_hash = hash_items(existing_items_dict)
        cache_key = get_cache_key("missing", request.country_code, request.program_type_id, items_hash)
        
        # ìºì‹œ í™•ì¸ (1ì‹œê°„ ìœ íš¨)
        cached_result = get_from_cache(cache_key, max_age_hours=1)
        if cached_result:
            return MissingItemsResponse(**cached_result)
        
        # ìºì‹œ ë¯¸ìŠ¤ - AI ë¶„ì„ ì‹¤í–‰
        print(f"ğŸ¤– AI ë¶„ì„ ì‹¤í–‰: missing-items")
        
        # ì¸ê¸° í†µê³„ ë°ì´í„° ì¡°íšŒ
        popularity_data = get_popularity_stats(request.country_code, request.program_type_id)
        
        # ëˆ„ë½ëœ í•­ëª© ì°¾ê¸°
        missing_items_data = find_missing_items(existing_items_dict, popularity_data)
        
        # ì‘ë‹µ ë°ì´í„° ìƒì„±
        missing_items = [
            MissingItem(
                item_title=item['item_title'],
                item_description=item['item_description'],
                item_tag=item['item_tag'],
                popularity_rate=item['popularity_rate'],
                avg_offset_days=item['avg_offset_days'],
                priority_score=item['priority_score'],
                missing_reason=item['missing_reason'],
                confidence_score=item['confidence_score']
            )
            for item in missing_items_data
        ]
        
        # ìš”ì•½ ë©”ì‹œì§€
        if len(missing_items) == 0:
            summary = "ğŸ‰ ì™„ë²½í•©ë‹ˆë‹¤! ëˆ„ë½ëœ í•­ëª©ì´ ì—†ì–´ìš”."
        elif len(missing_items) <= 2:
            summary = f"ğŸ’¡ {len(missing_items)}ê°œì˜ í•­ëª©ì„ ì¶”ê°€ë¡œ í™•ì¸í•´ë³´ì„¸ìš”."
        else:
            summary = f"âš ï¸ {len(missing_items)}ê°œì˜ ì¤‘ìš”í•œ í•­ëª©ì´ ëˆ„ë½ë˜ì—ˆì–´ìš”."
        
        result = MissingItemsResponse(
            missing_items=missing_items,
            total_missing=len(missing_items),
            recommendation_summary=summary
        )
        
        # ìºì‹œì— ì €ì¥
        save_to_cache(cache_key, result.model_dump())
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/recommendations/priority-reorder", response_model=PriorityReorderResponse)
async def reorder_priority(request: PriorityReorderRequest):
    """
    ìš°ì„ ìˆœìœ„ ì¬ì •ë ¬ API (ìºì‹œ ì ìš© + is_fixed í™œìš©)
    
    í˜„ì¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ì˜ í•­ëª©ë“¤ì„ ì¸ê¸°ë„ì™€ ê¸´ê¸‰ë„, is_fixed ê¸°ë°˜ìœ¼ë¡œ
    ìš°ì„ ìˆœìœ„ë¥¼ ì¬ì •ë ¬í•´ì„œ ì¶”ì²œ
    """
    try:
        # ìºì‹œ í‚¤ ìƒì„± (í˜„ì¬ í•­ëª© í•´ì‹œ + ì¶œêµ­ë‚ ì§œ í¬í•¨)
        current_items_dict = [item.model_dump() for item in request.current_items]
        items_hash = hash_items(current_items_dict)
        departure_hash = hashlib.md5(request.departure_date.encode()).hexdigest()[:6]
        cache_key = get_cache_key("reorder", request.country_code, request.program_type_id, f"{items_hash}_{departure_hash}")
        
        # ìºì‹œ í™•ì¸ (6ì‹œê°„ ìœ íš¨ - ìš°ì„ ìˆœìœ„ëŠ” ìì£¼ ì•ˆ ë°”ë€œ)
        cached_result = get_from_cache(cache_key, max_age_hours=6)
        if cached_result:
            return PriorityReorderResponse(**cached_result)
        
        # ìºì‹œ ë¯¸ìŠ¤ - AI ë¶„ì„ ì‹¤í–‰
        print(f"ğŸ¤– AI ë¶„ì„ ì‹¤í–‰: priority-reorder")
        
        # ì¶œêµ­ê¹Œì§€ ë‚¨ì€ ê¸°ê°„ ê³„ì‚°
        departure_date = datetime.strptime(request.departure_date, "%Y-%m-%d")
        days_until = (departure_date - datetime.now()).days
        
        # ì¸ê¸° í†µê³„ ë°ì´í„° ì¡°íšŒ
        popularity_data = get_popularity_stats(request.country_code, request.program_type_id)
        
        # ìš°ì„ ìˆœìœ„ ì¬ê³„ì‚° (is_fixed ê³ ë ¤)
        reordered_items_data = calculate_priority_scores(current_items_dict, request.departure_date, popularity_data)
        
        # ì‘ë‹µ ë°ì´í„° ìƒì„±
        reordered_items = [
            PriorityItem(
                title=item['title'],
                description=item['description'],
                tag=item['tag'],
                original_priority=item['original_priority'],
                ai_priority=item['ai_priority'],
                urgency_score=item['urgency_score'],
                reorder_reason=item['reorder_reason'],
                is_fixed=item['is_fixed']
            )
            for item in reordered_items_data
        ]
        
        # ìš”ì•½ ë©”ì‹œì§€
        fixed_count = sum(1 for item in reordered_items if item.is_fixed)
        if days_until <= 7:
            summary = f"âš ï¸ ì¶œêµ­ {days_until}ì¼ ì „! ê³ ì • ì¼ì • {fixed_count}ê°œ ìš°ì„  ì²˜ë¦¬"
        elif days_until <= 30:
            summary = f"ğŸ“‹ ì¶œêµ­ {days_until}ì¼ ì „, ê³ ì • í•­ëª© {fixed_count}ê°œ ë¨¼ì € í™•ì¸"
        else:
            summary = f"ğŸ“… ì¶œêµ­ {days_until}ì¼ ì „, ì—¬ìœ ë¡­ê²Œ ì¤€ë¹„ (ê³ ì • í•­ëª© {fixed_count}ê°œ)"
        
        result = PriorityReorderResponse(
            reordered_items=reordered_items,
            total_reordered=len(reordered_items),
            days_until_departure=days_until,
            reorder_summary=summary
        )
        
        # ìºì‹œì— ì €ì¥
        save_to_cache(cache_key, result.model_dump())
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/cache/status")
async def cache_status():
    """ìºì‹œ ìƒíƒœ í™•ì¸ (ë””ë²„ê¹…ìš©)"""
    cache_info = {}
    for key, value in cache_dict.items():
        age = datetime.now() - value['created']
        cache_info[key] = {
            "age_minutes": int(age.total_seconds() / 60),
            "created": value['created'].strftime("%Y-%m-%d %H:%M:%S")
        }
    
    return {
        "total_cached_items": len(cache_dict),
        "cache_details": cache_info
    }

@app.delete("/cache/clear")
async def clear_all_cache():
    """ëª¨ë“  ìºì‹œ ì‚­ì œ (ë””ë²„ê¹…ìš©)"""
    cleared_count = len(cache_dict)
    cache_dict.clear()
    return {"message": f"ëª¨ë“  ìºì‹œ ì‚­ì œ ì™„ë£Œ: {cleared_count}ê°œ í•­ëª©"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)